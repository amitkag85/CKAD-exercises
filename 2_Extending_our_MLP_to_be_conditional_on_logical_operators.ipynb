{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitkag85/CKAD-exercises/blob/master/2_Extending_our_MLP_to_be_conditional_on_logical_operators.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "\n",
        "Our goal is to extend our logical operation model in a couple ways:\n",
        "\n",
        "1. make a single model that can handle `AND`, `OR`, and `XOR`, depending on which one we ask for.\n",
        "2. make a model that will predict which logical operator was used, given the inputs and output.\n",
        "\n",
        "The main concepts this will demonstrate are making a model **conditional**, and predicting **probability distributions**."
      ],
      "metadata": {
        "id": "rM-dddGFIpqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fEBP4KOUiYe8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import ConcatDataset, Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Model: Multilayer Perceptron\n",
        "\n",
        "We'll define a simple multilayer perceptron ([MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) a.k.a. feedforward network) with one hidden layer. This will be a subclass of `torch.nn.Module`, which requires:\n",
        "* `__init__` with a call to `super().__init__()`\n",
        "* `forward()` which defines how to run the model given an input\n",
        "\n",
        "We will use the container [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) to glue all of our layers into a single module that passes the output from the previous step as the input to the next. Note that you must ensure that the output dimensions of the previous layer match the input dimensions of the next.\n",
        "\n",
        "The main component which makes neural networks able to learn non-linear functions are the [activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) places between the various layers. Since this model is very small and simple, we will be using [torch.nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid), which produces an \"S curve\" that squashes all values to the range 0.0 - 1.0."
      ],
      "metadata": {
        "id": "wufDKTo7xrL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.input_dim, self.hidden_dim),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(self.hidden_dim, self.output_dim),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # the `Sequential` can just be called on the input\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "-fKJ3Gtgxrdt"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device\n",
        "\n",
        "Torch supports multiple backends, most notibly `'cpu'` and `'cuda'` (with experimental support for Apple Metal as well). The main thing to remember is that all `Module`s and `Tensor`s neeed to be on the same device when running, or else you will get an error. Also note that all everything initially begins on CPU when created (with the exception of models that were saved while on GPU, but let's ignore that for now)."
      ],
      "metadata": {
        "id": "Df_tjsw9nJ7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the device we are using and save it for later. change the runtime\n",
        "# to GPU to see if print `cuda`\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# create a tensor and send it to our device\n",
        "x = torch.randn(2,3, device=device)\n",
        "print(x)\n",
        "# you can also send things to a device after they are creates\n",
        "x = torch.randn(2, 3)\n",
        "print(x)\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "\n",
        "# some operations, such as converting to a numpy array, require tensors\n",
        "# to be on the CPU specifically, so using `.cpu()` is helpful\n",
        "print(x.cpu().numpy())\n",
        "# there is also `.cuda()` but that asumesthat you actually have a GPU"
      ],
      "metadata": {
        "id": "a8XWWwmxnKEs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa31a3f4-b2d7-46c6-a9d3-5d14fa703f7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n",
            "tensor([[ 0.0682,  0.8186, -0.1895],\n",
            "        [ 1.0544,  1.8875, -0.5973]])\n",
            "tensor([[ 1.5405,  0.5023,  0.7658],\n",
            "        [-0.7287,  1.3163,  2.3349]])\n",
            "tensor([[ 1.5405,  0.5023,  0.7658],\n",
            "        [-0.7287,  1.3163,  2.3349]])\n",
            "[[ 1.5404756   0.502259    0.76583356]\n",
            " [-0.72872007  1.3163453   2.3348758 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset: Conditional Logic Operator\n",
        "\n"
      ],
      "metadata": {
        "id": "2iWUuzShp2a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPERATOR = {\n",
        "    'AND': [1, 0, 0],\n",
        "    'OR': [0, 1, 0],\n",
        "    'XOR': [0, 0, 1]\n",
        "}\n",
        "\n",
        "class LogicDataset(Dataset):\n",
        "  def __init__(self):\n",
        "      pass\n",
        "\n",
        "  def __len__(self):\n",
        "    # return the number of training examples\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # return the input/output for a given example (by index)\n",
        "    op = OPERATOR[self.op]\n",
        "    x = op + self.x[idx]\n",
        "    y = self.y[idx]\n",
        "    return {'x': torch.FloatTensor(x), 'y': torch.FloatTensor([y])}\n",
        "\n",
        "\n",
        "class AndDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'AND'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        0,\n",
        "        0,\n",
        "        1\n",
        "    ]\n",
        "\n",
        "\n",
        "class OrDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'OR'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        1\n",
        "    ]\n",
        "\n",
        "\n",
        "class XorDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'XOR'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        0\n",
        "    ]"
      ],
      "metadata": {
        "id": "9TK2NUybp2nY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ConcatDataset([AndDataset(), OrDataset(), XorDataset()])\n",
        "print(len(dataset))\n",
        "for x in dataset:\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "xss_e1kYkUl3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc4dd27-724c-430e-a8e9-84529337be0e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "{'x': tensor([1., 0., 0., 0., 0.]), 'y': tensor([0.])}\n",
            "{'x': tensor([1., 0., 0., 1., 0.]), 'y': tensor([0.])}\n",
            "{'x': tensor([1., 0., 0., 0., 1.]), 'y': tensor([0.])}\n",
            "{'x': tensor([1., 0., 0., 1., 1.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 1., 0., 0., 0.]), 'y': tensor([0.])}\n",
            "{'x': tensor([0., 1., 0., 1., 0.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 1., 0., 0., 1.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 1., 0., 1., 1.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 0., 1., 0., 0.]), 'y': tensor([0.])}\n",
            "{'x': tensor([0., 0., 1., 1., 0.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 0., 1., 0., 1.]), 'y': tensor([1.])}\n",
            "{'x': tensor([0., 0., 1., 1., 1.]), 'y': tensor([0.])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader and Batching\n",
        "\n"
      ],
      "metadata": {
        "id": "PCkwVhLqsNyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  x = batch['x']\n",
        "  y = batch['y']\n",
        "  print(x, 'x.size()', x.size())\n",
        "  print(y, 'y.size()', y.size())"
      ],
      "metadata": {
        "id": "U2GwzQWRsOiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "037b40ad-dde5-4164-8210-584003ec8627"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0., 0., 1.],\n",
            "        [0., 0., 1., 1., 0.],\n",
            "        [0., 1., 0., 0., 0.],\n",
            "        [1., 0., 0., 1., 0.],\n",
            "        [0., 0., 1., 1., 1.],\n",
            "        [0., 0., 1., 0., 1.],\n",
            "        [1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 1., 0.],\n",
            "        [0., 1., 0., 1., 1.],\n",
            "        [0., 0., 1., 0., 0.],\n",
            "        [0., 1., 0., 0., 1.],\n",
            "        [1., 0., 0., 1., 1.]]) x.size() torch.Size([12, 5])\n",
            "tensor([[0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.]]) y.size() torch.Size([12, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "rZX3m03zvwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import trange  # gives us a nice progress bar\n",
        "\n",
        "epochs = 10000  # the number of times to iterate through the training data\n",
        "\n",
        "model = MLP(5, 4, 1)  # create an instance of our model\n",
        "model = model.to(device)  # send the model to the appropriate device\n",
        "print(model.train())  # set the model to train mode (default) and print it for good measure\n",
        "opt = Adam(model.parameters())  # initialize the optimizer with the model parameters\n",
        "loss_fn = nn.MSELoss()  # create an instance of our loss function\n",
        "losses = []  # create an empty list for tracking the loss every epoch\n",
        "\n",
        "for epoch in trange(epochs):  # loop for the number of epochs\n",
        "  for batch in dataloader:  # iterate through the dataset\n",
        "\n",
        "    # get the inputs and target outputs and send them to the device\n",
        "    x = batch['x'].to(device)\n",
        "    y = batch['y'].to(device)\n",
        "\n",
        "    # run the model and get its prediction\n",
        "    y_hat = model(x)\n",
        "\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "\n",
        "    # clear the previous gradient from the optimizer\n",
        "    opt.zero_grad()\n",
        "    # calculate the gradient based on the loss\n",
        "    loss.backward()\n",
        "    # update the model weights based on the gradient\n",
        "    opt.step()\n",
        "\n",
        "    '''\n",
        "    Store the loss in a list so that we can plot it later.\n",
        "    When doing so however, we need to call `.detach()` in\n",
        "    order to remove the gradient, `.cpu()` to make sure it\n",
        "    is on the CPU, and `.numpy()` to convert it into a numpy\n",
        "    value because matplotlib doesn't work directly on tensors.\n",
        "    '''\n",
        "    losses.append(loss.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "LV-3ISDbsjmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d491943-9b2e-4da8-dbd3-b9728c1374d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (fc): Sequential(\n",
            "    (0): Linear(in_features=5, out_features=4, bias=True)\n",
            "    (1): LeakyReLU(negative_slope=0.01)\n",
            "    (2): Linear(in_features=4, out_features=1, bias=True)\n",
            "    (3): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:18<00:00, 536.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plvMl6o6zMSe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "83353bd5-eab6-40b2-dc01-de69948a2f0f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our training data is so small, we can iterate through all examples and compare the prediction to the target. For more complex datasets/tasks could use a test set to plot the validation loss, calculate a confusion matrix, etc."
      ],
      "metadata": {
        "id": "uWIj3DeKgbVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, example in enumerate(dataset):\n",
        "    x = example['x']\n",
        "    y = example['y']\n",
        "    y_hat = model(x)\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    print('x:', x, 'y:', y, 'y_hat:', y_hat, 'predicion:', y_hat.round(), 'loss:', loss)\n",
        "    if i % 4 == 3:\n",
        "      print('')"
      ],
      "metadata": {
        "id": "PnFPlJUBz4pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logic Operator Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "Qj2beAmMvNw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.input_dim, self.hidden_dim),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(self.hidden_dim, self.output_dim)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # the `Sequential` can just be called on the input\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "rSayE8cdxiAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "OPERATOR = {\n",
        "    'AND': 0,\n",
        "    'OR': 1,\n",
        "    'XOR': 2\n",
        "}\n",
        "\n",
        "class LogicDataset(Dataset):\n",
        "  def __init__(self):\n",
        "      pass\n",
        "\n",
        "  def __len__(self):\n",
        "    # return the number of training examples\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # return the input/output for a given example (by index)\n",
        "    x = self.x[idx] + [self.y[idx]]\n",
        "    y = OPERATOR[self.op]\n",
        "    return {'x': torch.FloatTensor(x), 'y': torch.LongTensor([y])}\n",
        "\n",
        "\n",
        "class AndDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'AND'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        0,\n",
        "        0,\n",
        "        1\n",
        "    ]\n",
        "\n",
        "\n",
        "class OrDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'OR'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        1\n",
        "    ]\n",
        "\n",
        "\n",
        "class XorDataset(LogicDataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.op = 'XOR'\n",
        "\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        0\n",
        "    ]"
      ],
      "metadata": {
        "id": "Kuoe_piVvNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = ConcatDataset([AndDataset(), OrDataset(), XorDataset()])\n",
        "print(len(dataset))\n",
        "for x in dataset:\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "8Hgi5Cw0vNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader and Batching\n",
        "\n"
      ],
      "metadata": {
        "id": "KCAoeQyMvNw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 12\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  x = batch['x']\n",
        "  y = batch['y']\n",
        "  print(x, 'x.size()', x.size())\n",
        "  print(y, 'y.size()', y.size())"
      ],
      "metadata": {
        "id": "CPhXSySevNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n"
      ],
      "metadata": {
        "id": "z2ZlG9jTvNw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import trange  # gives us a nice progress bar\n",
        "\n",
        "epochs = 10000  # the number of times to iterate through the training data\n",
        "\n",
        "model = MLP(3, 4, 3)  # create an instance of our model\n",
        "model = model.to(device)  # send the model to the appropriate device\n",
        "print(model.train())  # set the model to train mode (default) and print it for good measure\n",
        "opt = Adam(model.parameters())  # initialize the optimizer with the model parameters\n",
        "loss_fn = nn.CrossEntropyLoss()  # create an instance of our loss function\n",
        "losses = []  # create an empty list for tracking the loss every epoch\n",
        "\n",
        "for epoch in trange(epochs):  # loop for the number of epochs\n",
        "  for batch in dataloader:  # iterate through the dataset\n",
        "\n",
        "    # get the inputs and target outputs and send them to the device\n",
        "    x = batch['x'].to(device)\n",
        "    y = batch['y'].squeeze().to(device)\n",
        "\n",
        "    # run the model and get its prediction\n",
        "    y_hat = model(x)\n",
        "\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "\n",
        "    # clear the previous gradient from the optimizer\n",
        "    opt.zero_grad()\n",
        "    # calculate the gradient based on the loss\n",
        "    loss.backward()\n",
        "    # update the model weights based on the gradient\n",
        "    opt.step()\n",
        "\n",
        "    '''\n",
        "    Store the loss in a list so that we can plot it later.\n",
        "    When doing so however, we need to call `.detach()` in\n",
        "    order to remove the gradient, `.cpu()` to make sure it\n",
        "    is on the CPU, and `.numpy()` to convert it into a numpy\n",
        "    value because matplotlib doesn't work directly on tensors.\n",
        "    '''\n",
        "    losses.append(loss.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "tkWRLZjnvNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "oF0p8o2TvNw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our training data is so small, we can iterate through all examples and compare the prediction to the target. For more complex datasets/tasks could use a test set to plot the validation loss, calculate a confusion matrix, etc."
      ],
      "metadata": {
        "id": "wolxYzNrvNxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i, example in enumerate(dataset):\n",
        "    x = example['x']\n",
        "    y = example['y'].squeeze()\n",
        "    y_hat = model(x)\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    print('x:', x, 'y:', y, 'y_hat:', y_hat.softmax(dim=-1), 'predicion:', y_hat.argmax(dim=-1))\n",
        "    if i % 4 == 3:\n",
        "      print('')"
      ],
      "metadata": {
        "id": "aXlqx03ivNxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "xs = []\n",
        "y_hats = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for example in dataset:\n",
        "    x = example['x']\n",
        "    y_hat = model(x)\n",
        "\n",
        "    xs.append(x)\n",
        "    y_hats.append(y_hat)"
      ],
      "metadata": {
        "id": "oIG1MzZ3yVIi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(ncols=len(y_hats), sharey=True)\n",
        "\n",
        "for i, x in enumerate(y_hats):\n",
        "  ax[i].bar(range(3), y_hats[i].softmax(dim=-1))"
      ],
      "metadata": {
        "id": "7tf_-bnC2Tyg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}