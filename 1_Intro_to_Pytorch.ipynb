{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitkag85/CKAD-exercises/blob/master/1_Intro_to_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Introduction\n",
        "This is meant to be a fast paced introduction to machine learning using Pytorch. The goal is to get familiar with the basic aspects of building a model and train it on a supervised learning task."
      ],
      "metadata": {
        "id": "rM-dddGFIpqN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fEBP4KOUiYe8"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "[Tensors](https://pytorch.org/docs/stable/tensors.html) are (multidimensional) arrays, and are the core data type used in deep learning."
      ],
      "metadata": {
        "id": "fvV-soUFifAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a new tensor out of existing data\n",
        "t = torch.tensor([1,3,3,7])\n",
        "print(t)\n",
        "# get the the dimensions of a tensor\n",
        "print(t.size())\n",
        "# initialize a tensor of all ones of a particular size\n",
        "t = torch.ones(2, 3, 4)\n",
        "print(t)\n",
        "# `torch.Size` can be unpacked\n",
        "depth, height, width = t.size()\n",
        "print('depth:', depth, 'height:', height, 'width:', width)\n",
        "# tensors can be addressed just like numpy arrays\n",
        "print(t[0].size())\n",
        "# random, normally distributed tensors of a given size are also easy\n",
        "t = torch.randn(2,3)\n",
        "print(t)"
      ],
      "metadata": {
        "id": "UjqmeHYYiySh",
        "outputId": "8a062512-464c-414d-d8c6-83b5ed0c00f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 3, 3, 7])\n",
            "torch.Size([4])\n",
            "tensor([[[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]],\n",
            "\n",
            "        [[1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.],\n",
            "         [1., 1., 1., 1.]]])\n",
            "depth: 2 height: 3 width: 4\n",
            "torch.Size([3, 4])\n",
            "tensor([[ 0.4478,  0.2252, -0.3283],\n",
            "        [-1.5603, -1.2793,  0.6241]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modules\n",
        "\n",
        "Torch uses [Modules](https://pytorch.org/docs/stable/generated/torch.nn.Module.html) as the brimary building block for models. A `Module` can represent a layer or an entire model (models can be used as layers within other models).\n",
        "\n",
        "[torch.nn](https://pytorch.org/docs/stable/nn.html) is the primary library defining the most comong building blocks for most neural networks."
      ],
      "metadata": {
        "id": "66SVp7_TlEpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all basic layers/modules are defined in torch.nn\n",
        "import torch.nn as nn\n",
        "\n",
        "# a `Linear` layer (also called fully connected, or `Dense` in Keras)\n",
        "# is just y = Wx + b. `Linear` takes the input dimension, output dimensions\n",
        "# whether or not to include a bias term (default True)\n",
        "m = nn.Linear(2, 3)\n",
        "print(m)\n",
        "print('weight matrix:', m.weight.size())\n",
        "print('bias vector', m.bias.size())\n",
        "# you can create one without a bias as well\n",
        "m = nn.Linear(2, 3, bias=False)\n",
        "print(m)\n",
        "print('weight matrix:', m.weight.size())\n",
        "print('bias vector', m.bias)"
      ],
      "metadata": {
        "id": "92QW7Vn_lE6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Model: Multilayer Perceptron\n",
        "\n",
        "We'll define a simple multilayer perceptron ([MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron) a.k.a. feedforward network) with one hidden layer. This will be a subclass of `torch.nn.Module`, which requires:\n",
        "* `__init__` with a call to `super().__init__()`\n",
        "* `forward()` which defines how to run the model given an input\n",
        "\n",
        "We will use the container [torch.nn.Sequential](https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html#torch.nn.Sequential) to glue all of our layers into a single module that passes the output from the previous step as the input to the next. Note that you must ensure that the output dimensions of the previous layer match the input dimensions of the next.\n",
        "\n",
        "The main component which makes neural networks able to learn non-linear functions are the [activations](https://pytorch.org/docs/stable/nn.html#non-linear-activations-weighted-sum-nonlinearity) places between the various layers. Since this model is very small and simple, we will be using [torch.nn.Sigmoid](https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html#torch.nn.Sigmoid), which produces an \"S curve\" that squashes all values to the range 0.0 - 1.0."
      ],
      "metadata": {
        "id": "wufDKTo7xrL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.input_dim = input_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.output_dim = output_dim\n",
        "\n",
        "    self.fc = nn.Sequential(\n",
        "        nn.Linear(self.input_dim, self.hidden_dim),\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(self.hidden_dim, self.output_dim),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    # the `Sequential` can just be called on the input\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "-fKJ3Gtgxrdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Device\n",
        "\n",
        "Torch supports multiple backends, most notibly `'cpu'` and `'cuda'` (with experimental support for Apple Metal as well). The main thing to remember is that all `Module`s and `Tensor`s neeed to be on the same device when running, or else you will get an error. Also note that all everything initially begins on CPU when created (with the exception of models that were saved while on GPU, but let's ignore that for now)."
      ],
      "metadata": {
        "id": "Df_tjsw9nJ7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the device we are using and save it for later. change the runtime\n",
        "# to GPU to see if print `cuda`\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "# create a tensor and send it to our device\n",
        "x = torch.randn(2,3, device=device)\n",
        "print(x)\n",
        "# you can also send things to a device after they are creates\n",
        "x = torch.randn(2, 3)\n",
        "print(x)\n",
        "x = x.to(device)\n",
        "print(x)\n",
        "\n",
        "# some operations, such as converting to a numpy array, require tensors\n",
        "# to be on the CPU specifically, so using `.cpu()` is helpful\n",
        "print(x.cpu().numpy())\n",
        "# there is also `.cuda()` but that asumesthat you actually have a GPU"
      ],
      "metadata": {
        "id": "a8XWWwmxnKEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "The primary mechanisms for working with data live in [torch.utils.data](https://pytorch.org/docs/stable/data.html).\n",
        "\n",
        "Now we will make a model that solves [XOR](https://en.wikipedia.org/wiki/Exclusive_or). This will require creating:\n",
        "* a [map-style](https://pytorch.org/docs/stable/data.html#map-style-datasets) `Dataset` to hold our examples\n",
        "* a model to train\n",
        "* a training loop\n",
        "\n",
        "Although simple, XOR is useful as it requires a model that can handle non-linear relationships between inputs and outputs: it is not possible to draw a single straight line as a decision boundary."
      ],
      "metadata": {
        "id": "2iWUuzShp2a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "a `Dataset` is an interface for defining data to train on. it requires defining\n",
        "* __init__\n",
        "* __len__ to return the number of training examples\n",
        "* __getitem__ to return an example at a specific index\n",
        "'''\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class XorDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    # example inputs\n",
        "    self.x = [\n",
        "        [0, 0],\n",
        "        [1, 0],\n",
        "        [0, 1],\n",
        "        [1, 1]\n",
        "    ]\n",
        "    # example outputs\n",
        "    self.y = [\n",
        "        0,\n",
        "        1,\n",
        "        1,\n",
        "        0\n",
        "    ]\n",
        "\n",
        "  def __len__(self):\n",
        "    # return the number of training examples\n",
        "    return len(self.x)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    # return the input/output for a given example (by index)\n",
        "    x = self.x[idx]\n",
        "    y = self.y[idx]\n",
        "    return {'x': torch.FloatTensor(x), 'y': torch.FloatTensor([y])}\n",
        "\n",
        "xor_dataset = XorDataset()\n",
        "print(len(xor_dataset))\n",
        "print(xor_dataset[2])"
      ],
      "metadata": {
        "id": "9TK2NUybp2nY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DataLoader and Batching\n",
        "\n",
        "The most common way to work with a `Dataset` is to use a [DataLoader](https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader). This handles things like:\n",
        "* iterating through the `Dataset`\n",
        "* optionally randomizing the order of examples\n",
        "* batching examples together\n",
        "\n",
        "Batching (a.k.a. mini-batches) means loading multiple training examples in *parallel*. This is helpful, especially when using GPUs, for being able to do more computation in a single pass, speeding up traning for feedforward models. Additionally some objectives like contrastive learning specifically rely on batcfhing as part of the loss function. However recurrent models benefit less from batching as they take sequences as input, which often requires padding shorter examples since everything in the batch needs to be the same length."
      ],
      "metadata": {
        "id": "PCkwVhLqsNyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "dataloader = DataLoader(xor_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "for batch in dataloader:\n",
        "  x = batch['x']\n",
        "  y = batch['y']\n",
        "  print(x, 'x.size()', x.size())\n",
        "  print(y, 'y.size()', y.size())"
      ],
      "metadata": {
        "id": "U2GwzQWRsOiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Setup\n",
        "\n",
        "For supervised learning, we need:\n",
        "* a model to train\n",
        "* a dataset\n",
        "* an [optimizer](https://pytorch.org/docs/stable/optim.html)\n",
        "* an objective ([loss function](https://pytorch.org/docs/stable/nn.html#loss-functions))\n",
        "\n",
        "We then loop over all of our training data multiple times (epochs) and track the loss so that we can see how the model is improving. Of course you can (and usually should) also track validation loss on your test data, but we will omit that here.\n",
        "\n",
        "Here we will be using the [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam) optimizer and [mean squared error loss](https://pytorch.org/docs/stable/generated/torch.nn.MSELoss.html#torch.nn.MSELoss)."
      ],
      "metadata": {
        "id": "rZX3m03zvwp9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import trange  # gives us a nice progress bar\n",
        "\n",
        "epochs = 5000  # the number of times to iterate through the training data\n",
        "\n",
        "model = MLP(2, 2, 1)  # create an instance of our model\n",
        "model = model.to(device)  # send the model to the appropriate device\n",
        "print(model.train())  # set the model to train mode (default) and print it for good measure\n",
        "opt = Adam(model.parameters())  # initialize the optimizer with the model parameters\n",
        "loss_fn = nn.MSELoss()  # create an instance of our loss function\n",
        "losses = []  # create an empty list for tracking the loss every epoch\n",
        "\n",
        "for epoch in trange(epochs):  # loop for the number of epochs\n",
        "  for batch in dataloader:  # iterate through the dataset\n",
        "\n",
        "    # get the inputs and target outputs and send them to the device\n",
        "    x = batch['x'].to(device)\n",
        "    y = batch['y'].to(device)\n",
        "\n",
        "    # run the model and get its prediction\n",
        "    y_hat = model(x)\n",
        "\n",
        "    # calculate the loss\n",
        "    loss = loss_fn(y_hat, y)\n",
        "\n",
        "    # clear the previous gradient from the optimizer\n",
        "    opt.zero_grad()\n",
        "    # calculate the gradient based on the loss\n",
        "    loss.backward()\n",
        "    # update the model weights based on the gradient\n",
        "    opt.step()\n",
        "\n",
        "    '''\n",
        "    Store the loss in a list so that we can plot it later.\n",
        "    When doing so however, we need to call `.detach()` in\n",
        "    order to remove the gradient, `.cpu()` to make sure it\n",
        "    is on the CPU, and `.numpy()` to convert it into a numpy\n",
        "    value because matplotlib doesn't work directly on tensors.\n",
        "    '''\n",
        "    losses.append(loss.detach().cpu().numpy())"
      ],
      "metadata": {
        "id": "LV-3ISDbsjmO",
        "outputId": "cf08d7b4-5d51-4635-c557-8dd62b29aea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MLP' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-b6741e09c828>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m  \u001b[0;31m# the number of times to iterate through the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# create an instance of our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# send the model to the appropriate device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# set the model to train mode (default) and print it for good measure\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MLP' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plvMl6o6zMSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since our training data is so small, we can iterate through all examples and compare the prediction to the target. For more complex datasets/tasks could use a test set to plot the validation loss, calculate a confusion matrix, etc."
      ],
      "metadata": {
        "id": "uWIj3DeKgbVg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.cpu()\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for example in xor_dataset:\n",
        "    x = example['x']\n",
        "    y = example['y']\n",
        "    y_hat = model(x)\n",
        "    loss = loss_fn(y_hat, y)\n",
        "    print('x:', x, 'y:', y, 'y_hat:', y_hat, 'loss:', loss)"
      ],
      "metadata": {
        "id": "PnFPlJUBz4pe",
        "outputId": "a3ddb915-e37a-48be-ebb9-93bbe8dd5472",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d62fce25a1bb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mexample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxor_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus: Other Resources\n",
        "\n",
        "* [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy)'s Youtube Channel where he is currently building a minimal implementation of Pytorch from the ground up\n",
        "* [Yannic Kilcher](https://www.youtube.com/@YannicKilcher)'s Youtube channel where he has overviews of tons of papers, streams working on open source projects, and keeps up with current events in ML\n",
        "* [lucidrains](https://github.com/lucidrains) on github who implements absolutely everything"
      ],
      "metadata": {
        "id": "zv10mtUy20HY"
      }
    }
  ]
}